{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4ef473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DataFrame after Region_Group creation ---\n",
      "Region_Group\n",
      "Java             21168\n",
      "Sumatra          18948\n",
      "Sulawesi         11592\n",
      "Kalimantan        8904\n",
      "Maluku-Papua      7548\n",
      "Nusa Tenggara     5712\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import shap\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.model_selection import KFold # Import KFold\n",
    "\n",
    "# Define project root based on notebook location (assuming this part is correct for your setup)\n",
    "def find_project_root(current: Path, marker: str = \".git\"):\n",
    "    for parent in current.resolve().parents:\n",
    "        if (parent / marker).exists():\n",
    "            return parent\n",
    "    return current.resolve() # fallback\n",
    "\n",
    "PROJECT_ROOT = find_project_root(Path.cwd())\n",
    "RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "INTERIM_DIR = PROJECT_ROOT / \"data\" / \"interim\"\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "EXTERNAL_DIR = PROJECT_ROOT / \"data\" / \"external\"\n",
    "REPORTS_DIR = PROJECT_ROOT / \"reports\"\n",
    "FIGURES_DIR = REPORTS_DIR / \"figures\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "TABLES_DIR = REPORTS_DIR / \"tables\"\n",
    "\n",
    "# Load the data once outside the train function for efficiency in a sweep\n",
    "df = pd.read_csv(PROCESSED_DIR / \"INDONESIA\" /\"monthly_dengue_env_id.csv\")\n",
    "\n",
    "# --- REGION REASSIGNMENT (Keep this for consistency, but it won't be used for grouping) ---\n",
    "df['Region_Group'] = df['Region'].replace({'Maluku Islands': 'Maluku-Papua', 'Papua': 'Maluku-Papua'})\n",
    "print(\"--- DataFrame after Region_Group creation ---\")\n",
    "print(df['Region_Group'].value_counts())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "df['YearMonth'] = pd.to_datetime(df['YearMonth']) # Ensure YearMonth is datetime\n",
    "\n",
    "# Define variable categories\n",
    "env_vars = [\n",
    "    'temperature_2m', 'temperature_2m_min', 'temperature_2m_max',\n",
    "    'precipitation', 'potential_evaporation_sum', 'total_evaporation_sum',\n",
    "    'evaporative_stress_index', 'aridity_index',\n",
    "    'temperature_2m_ANOM', 'temperature_2m_min_ANOM', 'temperature_2m_max_ANOM',\n",
    "    'potential_evaporation_sum_ANOM', 'total_evaporation_sum_ANOM', 'precipitation_ANOM'\n",
    "]\n",
    "\n",
    "land_use_vars = [\n",
    "    'Class_70', 'Class_60', 'Class_50', 'Class_40', 'Class_95',\n",
    "    'Class_30', 'Class_20', 'Class_10', 'Class_90', 'Class_80'\n",
    "]\n",
    "\n",
    "climate_vars = ['ANOM1+2', 'ANOM3', 'ANOM4', 'ANOM3.4', 'DMI', 'DMI_East']\n",
    "target = 'Incidence_Rate'\n",
    "\n",
    "# Sort data by time and region\n",
    "df = df.sort_values(['YearMonth', 'ID_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215abfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Incidence Rate (IR)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['Incidence_Rate'], bins=30, kde=True, color='skyblue')\n",
    "plt.title('Histogram of Incidence Rate (IR)')\n",
    "plt.xlabel('Incidence Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da71510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of log-transformed Incidence Rate (IR)\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(np.log1p(df['Incidence_Rate']), bins=30, kde=True, color='salmon')\n",
    "plt.title('Histogram of log(Incidence Rate + 1)')\n",
    "plt.xlabel('log(Incidence Rate + 1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Incidence Rate (IR) with quantile separation\n",
    "quantiles = pd.qcut(df['Incidence_Rate'], 3, labels=['Low', 'Medium', 'High'])\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(data=df, x='Incidence_Rate', hue=quantiles, bins=30, palette=['green', 'orange', 'red'], multiple='stack')\n",
    "plt.title('Histogram of Incidence Rate (IR) by Quantile')\n",
    "plt.xlabel('Incidence Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print counts for each quantile\n",
    "print('Quantile counts:')\n",
    "print(quantiles.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Incidence Rate (IR) by quantile, showing only IR <= 50\n",
    "quantiles = pd.qcut(df['Incidence_Rate'], 3, labels=['Low', 'Medium', 'High'])\n",
    "df_plot = df[df['Incidence_Rate'] <= 50]\n",
    "quantiles_plot = quantiles[df['Incidence_Rate'] <= 50]\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(data=df_plot, x='Incidence_Rate', hue=quantiles_plot, bins=30, palette=['green', 'orange', 'red'], multiple='stack')\n",
    "plt.title('Histogram of Incidence Rate (IR â‰¤ 50) by Quantile')\n",
    "plt.xlabel('Incidence Rate')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print counts for each quantile (all data)\n",
    "print('Quantile counts (all data):')\n",
    "print(quantiles.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the value ranges for each quantile (low, medium, high)\n",
    "quantile_bins = pd.qcut(df['Incidence_Rate'], 3)\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "for i, interval in enumerate(quantile_bins.cat.categories):\n",
    "    print(f\"{labels[i]}: {interval.left:.2f} to {interval.right:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform IR, separate into three quantiles, and plot histogram\n",
    "log_IR = np.log1p(df['Incidence_Rate'])\n",
    "log_quantiles = pd.qcut(log_IR, 3, labels=['Low', 'Medium', 'High'])\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(x=log_IR, hue=log_quantiles, bins=30, palette=['green', 'orange', 'red'], multiple='stack')\n",
    "plt.title('Histogram of log(Incidence Rate + 1) by Quantile')\n",
    "plt.xlabel('log(Incidence Rate + 1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print counts for each quantile\n",
    "print('Quantile counts (log-transformed IR):')\n",
    "print(log_quantiles.value_counts().sort_index())\n",
    "\n",
    "# Print the value ranges for each quantile\n",
    "log_quantile_bins = pd.qcut(log_IR, 3)\n",
    "labels = ['Low', 'Medium', 'High']\n",
    "for i, interval in enumerate(log_quantile_bins.cat.categories):\n",
    "    print(f\"{labels[i]}: {interval.left:.2f} to {interval.right:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9293f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count cases above and below 2.1 per 100000 for Incidence Rate (before log transform)\n",
    "threshold = 2.1\n",
    "below = (df['Incidence_Rate'] < threshold).sum()\n",
    "above = (df['Incidence_Rate'] >= threshold).sum()\n",
    "print(f\"Cases below {threshold} per 100000: {below}\")\n",
    "print(f\"Cases above or equal to {threshold} per 100000: {above}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count cases where Incidence Rate is below 2.1 and exactly 0\n",
    "threshold = 2.1\n",
    "below_mask = df['Incidence_Rate'] < threshold\n",
    "zero_below = (df['Incidence_Rate'][below_mask] == 0).sum()\n",
    "print(f\"Cases below {threshold} per 100000 and exactly 0: {zero_below}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify IR into four quantiles: Near-zero, Low-risk, Mid-risk, High-risk\n",
    "classes = pd.Series(index=df.index, dtype='object')\n",
    "classes[df['Incidence_Rate'] == 0] = 'Near-zero'\n",
    "nonzero_mask = df['Incidence_Rate'] > 0\n",
    "nonzero_IR = df.loc[nonzero_mask, 'Incidence_Rate']\n",
    "nonzero_quantiles = pd.qcut(nonzero_IR, 3, labels=['Low-risk', 'Mid-risk', 'High-risk'])\n",
    "classes[nonzero_mask] = nonzero_quantiles.values\n",
    "\n",
    "# Print counts for each class\n",
    "print(classes.value_counts())\n",
    "\n",
    "# Optionally, show the value ranges for each nonzero class\n",
    "quantile_bins = pd.qcut(nonzero_IR, 3)\n",
    "labels = ['Low-risk', 'Mid-risk', 'High-risk']\n",
    "for i, interval in enumerate(quantile_bins.cat.categories):\n",
    "    print(f\"{labels[i]}: {interval.left:.2f} to {interval.right:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94265b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify IR into four quantiles based on log-transformed values\n",
    "log_IR = np.log1p(df['Incidence_Rate'])\n",
    "classes_log = pd.Series(index=df.index, dtype='object')\n",
    "classes_log[df['Incidence_Rate'] == 0] = 'Near-zero'\n",
    "nonzero_mask = df['Incidence_Rate'] > 0\n",
    "nonzero_log_IR = log_IR[nonzero_mask]\n",
    "nonzero_log_quantiles = pd.qcut(nonzero_log_IR, 3, labels=['Low-risk', 'Mid-risk', 'High-risk'])\n",
    "classes_log[nonzero_mask] = nonzero_log_quantiles.values\n",
    "\n",
    "# Print counts for each class\n",
    "print(classes_log.value_counts())\n",
    "\n",
    "# Show the value ranges for each nonzero class (log-transformed)\n",
    "quantile_bins_log = pd.qcut(nonzero_log_IR, 3)\n",
    "labels = ['Low-risk', 'Mid-risk', 'High-risk']\n",
    "for i, interval in enumerate(quantile_bins_log.cat.categories):\n",
    "    print(f\"{labels[i]}: {interval.left:.2f} to {interval.right:.2f} (log(IR+1))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add log-based class label to df and save\n",
    "\n",
    "df['IR_class_log'] = classes_log\n",
    "output_path = PROCESSED_DIR / 'monthly_dengue_env_id_with_class.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved DataFrame with IR_class_log to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3531df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be31ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee_dengue_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
